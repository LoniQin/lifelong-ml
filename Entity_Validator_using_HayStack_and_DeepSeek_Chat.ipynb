{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LoniQin/lifelong-ml/blob/main/Entity_Validator_using_HayStack_and_DeepSeek_Chat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3A_ZR8aKy8c"
      },
      "source": [
        "# Entity Validator using HayStack and DeepSeekChat\n",
        "\n",
        "This notebook demonstrates how to build an entity extraction pipeline using HayStack and DeepSeek Chat.\n",
        "\n",
        "## Steps:\n",
        "\n",
        "1. **Environment Setup:** Install Haystack and configure the DeepSeek Chat API key.\n",
        "2. **EntitiesValidator:** Create a custom component to validate extracted entities.\n",
        "3. **Prompt Template:** Define a prompt template to guide the language model.\n",
        "4. **Self-Reflecting Agent:** Build a Haystack pipeline that iteratively refines entity extraction using the language model and validator.\n",
        "5. **Tests:** Evaluate the pipeline on sample texts.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Environment Setup:\n",
        "Install Haystack and configure the DeepSeek Chat API key."
      ],
      "metadata": {
        "id": "9b6IUTjv_IX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-ai-haystack colorama"
      ],
      "metadata": {
        "id": "HCpA7kiGEqH2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from colorama import Fore\n",
        "from haystack import Pipeline, component\n",
        "from haystack.components.builders.prompt_builder import PromptBuilder\n",
        "from haystack_integrations.components.generators.google_ai import GoogleAIGeminiGenerator\n",
        "from google.colab import userdata\n",
        "import requests\n",
        "import os\n",
        "from haystack.components.generators.openai import OpenAIGenerator\n",
        "# Ignore all warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = DEEPSEEK_API_KEY"
      ],
      "metadata": {
        "id": "DcDnZTzy_lj2"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple usage of deepseek-chat"
      ],
      "metadata": {
        "id": "KgJ_7c5uYD3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAIGenerator(model=\"deepseek-chat\", api_base_url=\"https://api.deepseek.com\")\n",
        "llm.run(prompt=\"Tell me a joke\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hHFvTE5Xtcs",
        "outputId": "77664ff3-79ca-4f1d-d7ff-53ec225bccc7"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'replies': [\"Sure, here's a classic one:\\n\\nWhy don't scientists trust atoms?\\n\\nBecause they make up everything!\"],\n",
              " 'meta': [{'model': 'deepseek-chat',\n",
              "   'index': 0,\n",
              "   'finish_reason': 'stop',\n",
              "   'usage': {'completion_tokens': 27,\n",
              "    'prompt_tokens': 7,\n",
              "    'total_tokens': 34,\n",
              "    'prompt_cache_hit_tokens': 0,\n",
              "    'prompt_cache_miss_tokens': 7}}]}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: EntitiesValidator\n",
        "\n",
        "Create a custom component to validate extracted entities.\n",
        "* Create a custom Haystack component called EntitiesValidator.\n",
        "* This component checks if the extracted entities meet specific criteria (e.g., correct categories, no duplicates).\n",
        "* If the entities are valid, it marks them as 'DONE'. Otherwise, it prompts the language model for refinement."
      ],
      "metadata": {
        "id": "a_qEeWrxCoy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@component\n",
        "class EntitiesValidator:\n",
        "\n",
        "    @component.output_types(entities_to_validate=str, entities=str)\n",
        "    def run(self, replies: List[str]):\n",
        "        if 'DONE' in replies[0]:\n",
        "            return {\"entities\":replies[0].replace('DONE', '')}\n",
        "        else:\n",
        "            print(Fore.RED + \"Reflecting on entities\\n\", replies[0])\n",
        "            return {\"entities_to_validate\": replies[0]}"
      ],
      "metadata": {
        "id": "3hfVfe7iCrr4"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entities_validator = EntitiesValidator()\n",
        "entities_validator.run(replies= [\"{'name': 'Tuana'}\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8mQaaKLNacj",
        "outputId": "15992e70-e280-44a2-9df3-26b999545013"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mReflecting on entities\n",
            " {'name': 'Tuana'}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'entities_to_validate': \"{'name': 'Tuana'}\"}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entities_validator.run(replies= [\"DONE {'name': 'Tuana'}\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFU6PUSzNcio",
        "outputId": "2ed924cd-f435-4bf2-a468-1cdd3add0b4d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'entities': \" {'name': 'Tuana'}\"}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Prompt Template\n",
        "\n",
        "Define a prompt template to guide the language model.\n",
        "* Define a prompt template using Jinja2 syntax.\n",
        "* The template guides the language model on how to * extract entities and provides feedback based on the EntitiesValidator's output.\n",
        "* It includes conditional logic to handle both initial entity extraction and subsequent refinements."
      ],
      "metadata": {
        "id": "yO28pmx2NkCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\"\n",
        "{% if entities_to_validate %}\n",
        "    Here was the text you were provided:\n",
        "    {{ text }}\n",
        "    Here are the entities you previously extracted:\n",
        "    {{ entities_to_validate[0] }}\n",
        "    Are these the correct entities?\n",
        "    Things to check for:\n",
        "    - Entity categories should exactly be \"Person\", \"Location\" and \"Date\"\n",
        "    - There should be no extra categories\n",
        "    - There should be no duplicate entities\n",
        "    - If there are no appropriate entities for a category, the category should have an empty list\n",
        "    If you are done say 'DONE' and return your new entities in the next line\n",
        "    If not, simply return the best entities you can come up with.\n",
        "    Entities:\n",
        "{% else %}\n",
        "    Extract entities from the following text\n",
        "    Text: {{ text }}\n",
        "    The entities should be presented as key-value pairs in a JSON object.\n",
        "    Example:\n",
        "    {\n",
        "        \"Person\": [\"value1\", \"value2\"],\n",
        "        \"Location\": [\"value3\", \"value4\"],\n",
        "        \"Date\": [\"value5\", \"value6\"]\n",
        "    }\n",
        "    If there are no possibilities for a particular category, return an empty list for this\n",
        "    category\n",
        "    Entities:\n",
        "{% endif %}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "p4wZ4QtjNhFE"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Self-Reflecting Agent\n",
        "\n",
        "* Build a Haystack pipeline that orchestrates the entity extraction process.\n",
        "* The pipeline connects the prompt builder, entities validator, and language model (DeepSeek Chat).\n",
        "* It allows for iterative refinement, where the language model receives feedback and improves its entity extraction based on the validator's output."
      ],
      "metadata": {
        "id": "jT12DbWnNrEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptBuilder(template=template)\n",
        "llm = OpenAIGenerator(model=\"deepseek-chat\", api_base_url=\"https://api.deepseek.com\")\n",
        "entities_validator = EntitiesValidator()\n",
        "\n",
        "agent = Pipeline(max_loops_allowed=10)\n",
        "\n",
        "agent.add_component(\"prompt_builder\", prompt_template)\n",
        "agent.add_component(\"entities_validator\", entities_validator)\n",
        "agent.add_component(\"llm\", llm)\n",
        "\n",
        "agent.connect(\"prompt_builder.prompt\", \"llm.prompt\")\n",
        "agent.connect(\"llm.replies\", \"entities_validator.replies\")\n",
        "agent.connect(\"entities_validator.entities_to_validate\", \"prompt_builder.entities_to_validate\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCnQ8Z57NukD",
        "outputId": "2cc2a191-fa75-4a46-d7f9-c8e323416193"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<haystack.core.pipeline.pipeline.Pipeline object at 0x7d437c8d99f0>\n",
              "ðŸš… Components\n",
              "  - prompt_builder: PromptBuilder\n",
              "  - entities_validator: EntitiesValidator\n",
              "  - llm: OpenAIGenerator\n",
              "ðŸ›¤ï¸ Connections\n",
              "  - prompt_builder.prompt -> llm.prompt (str)\n",
              "  - entities_validator.entities_to_validate -> prompt_builder.entities_to_validate (str)\n",
              "  - llm.replies -> entities_validator.replies (List[str])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Tests\n",
        "\n",
        "Evaluate the pipeline on sample texts.\n",
        "\n",
        "* Evaluate the performance of the pipeline on sample texts.\n",
        "* Print the final extracted entities in green to indicate successful validation."
      ],
      "metadata": {
        "id": "RKZWcbW5RpWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "Istanbul is the largest city in Turkey, straddling the Bosporus Strait,\n",
        "the boundary between Europe and Asia. It is considered the country's economic,\n",
        "cultural and historic capital. The city has a population of over 15 million residents,\n",
        "comprising 19% of the population of Turkey,[4] and is the most populous city in Europe\n",
        "and the world's fifteenth-largest city.\"\"\"\n",
        "\n",
        "result = agent.run({\"prompt_builder\": {\"text\": text}})\n",
        "print(Fore.GREEN + result['entities_validator']['entities'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Rd1k0CJRrSt",
        "outputId": "325f1438-fb0f-4daf-e56e-4861d616346e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mReflecting on entities\n",
            " ```json\n",
            "{\n",
            "    \"Person\": [],\n",
            "    \"Location\": [\"Istanbul\", \"Turkey\", \"Bosporus Strait\", \"Europe\", \"Asia\"],\n",
            "    \"Date\": []\n",
            "}\n",
            "```\n",
            "\u001b[32mBased on the provided text, the correct entities categorized as \"Person\", \"Location\", and \"Date\" are as follows:\n",
            "\n",
            "Entities:\n",
            "- Person: []\n",
            "- Location: [\"Istanbul\", \"Turkey\", \"Europe\", \"Bosporus Strait\"]\n",
            "- Date: []\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "Stefano: Hey all, let's start the all hands for June 6th 2024\n",
        "Geoff: Thanks, I'll kick it off with a request. Could we please add persistent memory to the Chroma document store.\n",
        "Stefano: Easy enough, I can add that to the feature requests. What else?\n",
        "Julain: There's a bug, some BM25 algorithms return negative scores and we filter them out from the results by default.\n",
        "Instead, we should probably check which algorithm is being used and keep results with negative scores accordingly.\n",
        "Esmail: Before we end this call, we should add a new Generator component for LlamaCpp in the next release.\n",
        "Tuana: Thanks all, I think we're done here, we can create some issues in GitHub about these.\"\"\"\n",
        "\n",
        "result = agent.run({\"prompt_builder\": {\"text\": text}})\n",
        "print(Fore.GREEN + result['entities_validator']['entities'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9R4Y-E0Y8UY",
        "outputId": "d590f500-a26a-4f4e-8b09-0bb6f6ba554a"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mReflecting on entities\n",
            " ```json\n",
            "{\n",
            "    \"Person\": [\"Stefano\", \"Geoff\", \"Julain\", \"Esmail\", \"Tuana\"], \n",
            "    \"Location\": [], \n",
            "    \"Date\": [\"June 6th 2024\"]\n",
            "}\n",
            "```\n",
            "\u001b[32m\n",
            "Entities:\n",
            "{\n",
            "  \"Person\": [\"Stefano\", \"Geoff\", \"Julain\", \"Esmail\", \"Tuana\"],\n",
            "  \"Location\": [],\n",
            "  \"Date\": [\"June 6th 2024\"]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Conclusion\n",
        "\n",
        "This notebook demonstrated how to build a self-reflecting entity extraction pipeline using Haystack and DeepSeek Chat.\n",
        "The pipeline iteratively refines entity extraction using a language model and a custom validator, ensuring high-quality results.\n",
        "This approach can be applied to various entity extraction tasks, improving accuracy and efficiency in natural language processing applications."
      ],
      "metadata": {
        "id": "aBuQZ3K3dLRJ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkuqEM3k9f1FIvH85Q1LwJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}